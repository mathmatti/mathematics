\chapter{Momento angolare}
\section{Rotazioni}
Le rotazioni tridimensionali sono trasformazioni lineari di $\R^3$ che preservano la lunghezza dei vettori e l'orientazione.
Esse formano un gruppo, poich\'e la composizione di due rotazioni è associativa e dà ancora una rotazione, esiste l'elemento neutro (che è l'identità di $\R^3$) e ogni rotazione ha un'unica inversa.
Esso ha inoltre una struttura di varietà differenziabile, per cui le operazioni di gruppo sono $\cclass[\infty]$, e ciò lo rende un gruppo di Lie.
In una base ortonormale di $\R^3$ queste rotazioni sono associate a matrici reali $3\times 3$ ortogonali con determinante 1: il gruppo delle rotazioni si identifica dunque con il gruppo $SO(3)$, dotato dell'operazione di moltiplicazione tra matrici.

\paragraph{Parametrizzazione asse-angolo}
Ogni rotazione non banale ammette sempre un autospazio di dimensione 1, che corrisponde all'asse di rotazione; essa agisce come una rotazione bidimensionale nel piano ortogonale a tale asse.
Siccome ogni rotazione di $\R^2$ è univocamente determinata dall'angolo, una rotazione di $\R^3$ è univocamente determinata dall'asse di rotazione (a cui è associato un versore $\axis$) e dall'angolo: questo fornisce tre gradi di libertà alle rotazioni.
Indichiamo dunque una rotazione con $\Rot(\axis,\theta)$, oppure più brevemente con $\Rot(\vtheta)$ definendo il vettore $\vtheta\defeq\theta\axis$.\footnote{Il verso di $\axis$ determina anche il verso della rotazione: convenzionalmente una rotazione di un angolo positivo è antioraria attorno all'asse specificato.}
Abbiamo le seguenti tre proprietà, che si possono visualizzare facilmente:
\begin{itemize}
	\item $\Rot(-\axis,-\theta)=\Rot(\axis,\theta)$, per cui possiamo considerare solo rotazioni con $\theta>0$;
	\item $\Rot(\axis,\pi+\theta)=\Rot(-\axis,\pi-\theta)$, per cui possiamo ulteriormente restringere $\theta$ all'intervallo tra $0$ e $\pi$, inclusi;
	\item $\Rot(\axis,0)$, qualsiasi sia l'asse, non compie una rotazione ed è quindi l'identità.
\end{itemize}
Con queste si dimostra che ciascuna rotazione è caratterizzata in modo univoco da un angolo $\theta\in[0,\pi]$ e un versore $\axis$
\begin{itemize}
	\item arbitrario se $\theta=0$;
	\item unico se $0<\theta<\pi$;
	\item unico a meno del segno se $\theta=\pi$.
\end{itemize}

\paragraph{Generatori del gruppo}
Fissato l'asse di rotazione $\axis$, la mappa $t\mapsto\Rot(\axis,t)$, per $t\in\R$, è un sottogruppo (abeliano) a un parametro di $SO(3)$.
Indicando con il punto la derivata rispetto all'argomento, da ciascun sottogruppo possiamo ricavare un (unico) elemento dello spazio tangente all'identità $\Id$ del gruppo, come di seguito.
Sfruttando la composizione di rotazioni, all'interno del sottogruppo, data da $\Rot(\axis,t_1)\Rot(\axis,t_2)=\Rot(\axis,t_1+t_2)$, risulta infatti
\begin{equation}
	\dot{\Rot}(\axis,t)=\lim_{h\to 0}\frac{\Rot(\axis,t+h)-\Rot(\axis,t)}{h}=\Rot(\axis,t)\lim_{h\to 0}\frac{\Rot(\axis,h)-\Id}{h}=\Rot(\axis,t)\dot{\Rot}(\axis,0)
	\label{eq:derivata-rotazione}
\end{equation}
che con l'ovvia condizione al contorno $\Rot(\axis,0)=\Id$ è un'equazione differenziale per $\Rot(\axis,t)$ che ha come soluzione
\begin{equation}
	\Rot(\axis,t)=\exp\Big(t\dot{\Rot}(\axis,0)\Big).
	\label{eq:rotazione-esponenziale}
\end{equation}
L'elemento $\dot{\Rot}(\axis,0)$, che indicheremo d'ora in poi con $\Ang(\axis)$, è detto \emph{generatore} del sottogruppo, e rappresenta il vettore tangente in $\Id$ alla curva descritta sul gruppo dalla mappa $t\mapsto\Rot(\axis,t)$.
Analizziamo quindi lo spazio tangente all'identità: esso è uno spazio vettoriale (reale) di dimensione 3, che è la dimensione di $SO(3)$.\footnote{La dimensione del gruppo è intesa come dimensione di una varietà differenziabile: $SO(3)$ \emph{non} è uno spazio vettoriale.}
Possiamo individuare allora una sua base di tre elementi: se come assi di rotazione prendiamo i tre assi cartesiani (con i versori $\axis=\vec e_i$), troviamo tre sottogruppi a un parametro che hanno come generatori tre elementi $\Ang_i\defeq\Ang(\vec e_i)=\dot{\Rot}(\vec e_i,0)$.
Calcoliamo il primo elemento: partendo dalla matrice di rotazione attorno all'asse individuato da $\vec e_1$ abbiamo\footnote{
	C'è da fare attenzione a distinguere tra rotazioni passive o attive, poich\'e la forma della matrice è diversa.
	In questo caso, la matrice ruota la base canonica di $\R^3$ (lasciando fisso $\vec e_1$), e di conseguenza i vettori delle coordinate si trasformano con la trasposta della matrice.}
\begin{equation}
	\Rot(\vec e_1,t)=
	\begin{bmatrix}
		1	&0		&0		\\
		0	&\cos t	&-\sin t\\
		0	&\sin t	&\cos t
	\end{bmatrix}
	\qqq
	\Ang_1=\dot{\Rot}(\vec e_1,0)=
	\begin{bmatrix}
		0	&0	&0	\\
		0	&0	&-1	\\
		0	&1	&0
	\end{bmatrix}.
\end{equation}
Una volta ricavati anche $\Ang_2$ e $\Ang_3$ è immediato vedere che sono tre elementi linearmente indipendenti, perciò $\{\Ang_1,\Ang_2,\Ang_3\}$ è una base dello spazio tangente a $\Id$.
Presa una rotazione infinitesima, ossia nell'intorno di $\Id$, possiamo approssimarla linearmente come
\begin{equation}
	\Rot(\vtheta)=\Id+\sum_{i=1}^3\theta_i\Ang_i
	\label{eq:rotazione-infinitesima}
\end{equation}
trascurando cioè i termini di ordine superiore al primo.
Essi soddisfano inoltre le relazioni, per $i,j,k\in\{1,2,3\}$,
\begin{equation}
	[\Ang_i,\Ang_j]=\epsilon_{ijk}\Ang_k
	\label{eq:parentesi-lie-so3}
\end{equation}
che completano la descrizione dell'algebra di Lie del gruppo delle rotazioni, indicata con $\mathfrak{so}(3)$: essa è in pratica lo spazio vettoriale delle matrici $3\times 3$ reali antisimmetriche.

\subsection{Rotazione di stati e operatori}
Vediamo dunque come applicare la teoria delle rotazioni che stiamo studiando allo spazio di Hilbert degli stati.
Cosa vuol dire «ruotare uno stato»?
Certamente non significa ruotare il vettore dello spazio di Hilbert, e nemmeno ad esempio la sua funzione d'onda nello spazio; la rotazione agisce sullo spazio tridimensionale, e sono gli elementi di questo spazio ad essere ruotati.
Dobbiamo quindi studiare le rappresentazioni del gruppo: in questo modo associamo ad ogni rotazione $\Rot$ un operatore $\op U(\Rot)$ che agisce sugli stati ruotandoli: se $\ket{\Rot\psi}$ indica lo stato $\ket{\psi}$ ruotato, allora $\ket{\Rot\psi}=\op U(\Rot)\ket{\psi}$.
Questa rappresentazione dovrà essere unitaria, in modo che la rotazione conservi le probabilità, dunque richiediamo che $\adj{\op U(\Rot)}=\op U(\Rot)^{-1}$.
Come già visto nell'evoluzione temporale, possiamo ``trasferire'' la rotazione degli stati agli operatori, descrivendo una rotazione anche di questi.
Definiamo cos\`i la rotazione di un operatore ponendo che il valore di aspettazione dell'operatore iniziale rispetto allo stato iniziale sia uguale al valore di aspettazione dell'operatore ruotato rispetto allo stato ruotato; in altre parole, detto $\op a$ l'operatore e $\op a'$ quello ruotato, richiediamo che
\begin{equation}
	\bra{\psi}\op a\ket{\psi}=\bra{\Rot\psi}\op a'\ket{\Rot\psi}=\bra{\psi}\op U(\Rot)^{-1}\op a'\op U(\Rot)\ket{\psi}
\end{equation}
ossia, per l'arbitriaretà di $\ket{\psi}$,
\begin{equation}
	\op U(\Rot)^{-1}\op a'\op U(\Rot)=\op a.
	\label{eq:rotazione-operatore}
\end{equation}
Possiamo dunque classificare gli operatori come
\begin{itemize}
	\item \emph{scalari}, se sono invarianti per rotazioni, ossia $\op U(\Rot)^{-1}\op s\op U(\Rot)=\op s$;
	\item \emph{vettoriali}, se ruotano come un vettore di $\R^3$ sotto l'azione della matrice $\Rot_{ij}\in SO(3)$, vale a dire $\op U(\Rot)^{-1}\op v_i\op U(\Rot)=\Rot_{ij}\op v_j$ dove i $\op v_k$ sono le tre componenti dell'operatore $\op{\vec v}=(\op v_1,\op v_2,\op v_3)$.
\end{itemize}
Gli operatori di posizione e impulso, ad esempio, sono entrambi vettoriali.

Come per le rotazioni di $SO(3)$, anche per le rappresentazioni possiamo trovare una terna di generatori $\op J_1,\op J_2,\op J_3$ con simili proprietà: questo equivale a trovare una rappresentazione dell'algebra $\mathfrak{so}(3)$.
Cos\`i come possiamo passare da un elemento dell'algebra al gruppo tramite l'esponenziale, una transizione analoga si ha per le relative rappresentazioni, ma il discorso è più delicato: non è vero in generale che ogni rappresentazione dell'algebra, composta con l'esponenziale, dà una rappresentazione del gruppo.
Questo lo vedremo esplicitamente più avanti proprio con le rotazioni.

La prima rappresentazione che possiamo trovare di $\mathfrak{so}(3)$ è ovviamente quella che abbiamo visto finora, che è la rappresentazione \emph{fondamentale}: ha dimensione 3 e si hanno le matrici $\Ang_i$ già viste.
In questo particolare caso, è vero che esponenziando un elemento dell'algebra si ottiene un elemento di $SO(3)$: dato un versore $(n_1,n_2,n_3)$ l'elemento $\mathsf N=n_1\Ang_1+n_2\Ang_2+n_3\Ang_3$ genera il sottogruppo a un parametro delle rotazioni attorno all'asse individuato da $\axis$, e con $\exp(t\mathsf N)$ per $t\in\R$ si hanno tutte le rotazioni di tale sottogruppo.

\subsection{Le matrici di Pauli}
Un'altra rappresentazione cruciale di $\mathfrak{so}(3)$ si ottiene con le matrici di Pauli
\begin{equation}
	\sigma_1=
	\begin{bmatrix}
		0&1\\1&0
	\end{bmatrix},
	\hspace{1cm}
	\sigma_2=
	\begin{bmatrix}
		0&-i\\i&0
	\end{bmatrix},
	\hspace{1cm}
	\sigma_3=
	\begin{bmatrix}
		1&0\\0&-1
	\end{bmatrix}.
	\label{eq:matrici-pauli}
\end{equation}
Esse soddisfano la relazione, per $j,k,l\in\{1,2,3\}$,
\begin{equation}
	\sigma_j\sigma_k=\delta_{jk}+i\epsilon_{jkl}\sigma_l
	\label{eq:prodotto-matrici-pauli}
\end{equation}
da cui $\sigma_1^2=\sigma_2^2=\sigma_3^2=1$, $\sigma_1\sigma_2\sigma_3=i$ e
\begin{equation}
	[\sigma_j,\sigma_k]=2i\epsilon_{jkl}\sigma_l.
	\label{eq:commutatore-matrici-pauli}
\end{equation}
Queste tre matrici generano lo spazio vettoriale (reale) delle matrici $2\times 2$ complesse hermitiane con traccia nulla, che indichiamo con $H_0$, che con la parentesi di Lie data dalla \eqref{eq:commutatore-matrici-pauli} è anche un'algebra di Lie.
La mappa $\Gamma\colon\mathfrak{so}(3)\to H_0$ data da\footnote{
	Trattandosi di una mappa tra spazi vettoriali, è sufficiente definirla sulla base dello spazio di partenza.
}
\begin{equation}
	\Gamma(\Ang_k)=\sigma_k
	\label{eq:rappresentazione-so3-matrici-pauli}
\end{equation}
per $k=1,2,3$ è dunque una rappresentazione dell'algebra che stiamo studiando.
Notiamo inoltre che le matrici $-\frac{i}2\sigma_k$ sono una base per l'algebra $\mathfrak{su}(2)$, associata al gruppo di Lie $SU(2)$ delle matrici unitarie con determinante 1: la mappa $\phi\colon H_0\to SU(2)$ data da $\phi(a)=\exp(-ia/2)$ ci permette dunque di associare una matrice di $SU(2)$ a una combinazione lineare reale delle matrici di Pauli.

In particolare vediamo come, dato un versore $\axis$ e un angolo $\theta$, si può associare ad ogni rotazione $\Rot(\axis,\theta)$ una matrice
\begin{equation}
	\cos\frac{\theta}2-i\scalar{\vsigma}{\axis}\sin\frac{\theta}2
\end{equation}
dove $\scalar{\vsigma}{\axis}$ è un'abbreviazione per $n_1\sigma_1+n_2\sigma_2+n_3\sigma_3$.
Prendiamo la combinazione lineare $-\frac{it}2\scalar{\vsigma}{\axis}$: essa è una matrice di $\mathfrak{su}(3)$, perciò il suo esponenziale appartiene a $SU(2)$.
Con lo sviluppo in serie di Taylor troviamo e separando la somma delle potenze pari da quelle dispari troviamo
\begin{equation}
	\begin{split}
		\exp\big(-\frac{i}2\scalar{\vsigma}{\axis}t\big)&=\sum_{k=0}^{+\infty}\frac{(-i\scalar{\vsigma}{\axis}t/2)^k}{k!}=\\
		&=\sum_{j=0}^{+\infty}\frac{(-i\scalar{\vsigma}{\axis}t/2)^{2j}}{(2j)!}+\sum_{j=0}^{+\infty}\frac{(-i\scalar{\vsigma}{\axis}t/2)^{2j+1}}{(2j+1)!}=\\
		&=\sum_{j=0}^{+\infty}\frac{(-it/2)^{2j}}{(2j)!}+\scalar{\vsigma}{\axis}\sum_{j=0}^{+\infty}\frac{(-it/2)^{2j+1}}{(2j+1)!}=\\
		&=\sum_{j=0}^{+\infty}\frac{(-1)^j(t/2)^{2j}}{(2j)!}-i\scalar{\vsigma}{\axis}\sum_{j=0}^{+\infty}\frac{(-1)^j(t/2)^{2j+1}}{(2j+1)!}=\\
		&=\cos\frac{t}2-i\scalar{\vsigma}{\axis}\sin\frac{t}2.
	\end{split}
	\label{eq:formula-eulero-SU2}
\end{equation}
Abbiamo sfruttato in questo calcolo il fatto che, per ogni $n\in\N_0$, $(\scalar{\vsigma}{\axis})^{2n}=\norm{\axis}^{2n}=1$: questo si vede facilmente perch\'e sviluppando il quadrato di $n_1\sigma_1+n_2\sigma_2+n_3\sigma_3$ si hanno i termini quadratici $n_k^2\sigma_k^2=n_k^2$ mentre i prodotti misti $n_jn_k(\sigma_j\sigma_k+\sigma_k\sigma_j)$ sono nulli, come si deduce dalla \eqref{eq:prodotto-matrici-pauli}.

Notiamo poi che la forma bilineare $g\colon H_0\times H_0\to\C$ data da
\begin{equation}
	g(a,b)=\frac12\tr(ab)
	\label{eq:prodotto-interno-matrici-pauli}
\end{equation}
definisce un prodotto interno in $H_0$, rispetto al quale le tre matrici di Pauli sono ortonormali: con la \eqref{eq:prodotto-matrici-pauli} si ha
\begin{equation}
	\frac12\tr(\sigma_j\sigma_k)=\frac12\tr(\delta_{jk}+i\epsilon_{jkl}\sigma_l)=\frac12\tr\delta_{jk}+\frac12\epsilon_{jkl}\tr(i\sigma_l)=\frac12\tr\delta_{jk}=\delta_{jk}.
\end{equation}
Questo risultato è utile per ``estrarre'' i coefficienti di una combinazione lineare delle tre matrici: se $a\in H_0$ si scrive come $\mu_1\sigma_1+\mu_2\sigma_2+\mu_3\sigma_3$, allora $\mu_k=g(a,\sigma_k)=\frac12\tr(a\sigma_k)$.

Ora, presa una matrice $U\in SU(2)$, definiamo la mappa
\begin{equation}
	\rho_U\colon x\mapsto Ux\adj{U},
\end{equation}
evidentemente lineare, per $x\in H_0$.
Poich\'e $\adj{(Ux\adj{U})}=\adj{(\adj U)}\adj{x}\adj{U}=Ux\adj{U}$ e $\tr(Ux\adj{U})=\tr(\adj{U}Ux)=\tr x=0$, il risultato è ancora un elemento di $H_0$, perciò $\rho_U$ è un endomorfismo di $H_0$.
Se definiamo una mappa $\rho_V\colon x\mapsto Vx\adj{V}$  per un'altra $V\in SU(2)$ in modo analogo, componendo le due risulta
\begin{equation}
	\rho_V\circ\rho_U(x)=V\rho_U(x)\adj{V}=VUx\adj{U}\adj{V}=VUx\adj{(VU)}=\rho_{VU}(x)
\end{equation}
che fornisce una legge di composizione di questa ``famiglia'' di mappe.
D'altra parte, abbiamo visto che $H_0\cong\R^3$, quindi il vettore $(x_1,x_2,x_3)$ delle coordinate di $x$ rispetto alle tre $\sigma_k$ è un vettore di $\R^3$, e risulta inoltre che
\begin{equation}
	\det(x_k\sigma_k)=-x_3^2-(x_1-ix_2)(x_1+ix_2)=-x_3^2-x_1^2-x_2^2=-\norm{x}^2.
\end{equation}
Applicando $\rho_U$ alla matrice $x_k\sigma_k$ risulta anche, per l'unitarietà di $U$,
\begin{equation}
	\det\rho_U(x)=\det(Ux\adj{U})=\det x
\end{equation}
quindi, vista come mappa lineare $\R^3\to\R^3$, $\rho_U$ è un'isometria, vale a dire $\rho_U\in O(3)$.
L'analogia tra $\rho_U$ e una rotazione è sempre più evidente.
Calcoliamo infine la matrice $P$ associata a $\rho_U$, tale che $x_k'=P_{kj}x_j$, dove $x'$ è il vettore delle coordinate di $\rho_U(x)$: siccome
\begin{equation}
	\rho_U(x)=Ux\adj{U}=x_iU\sigma_i\adj{U}=x_i(P^T)_{ij}\sigma_j=x_iP_{ji}\sigma_i
\end{equation}
abbiamo che
\begin{equation}
	P_{ji}=(P^T)_{ij}=\frac12\tr(\sigma_jU\sigma_i\adj{U}).
\end{equation}
Parametrizzando $U$ con la formula \eqref{eq:formula-eulero-SU2}: esistono un versore $\axis$ e un $\theta\in\R$ tali che
\begin{equation}
	\begin{split}
		U\sigma_i\adj{U}&=\bigg(\!\cos\frac{\theta}2-i\scalar{\vsigma}{\axis}\sin\frac{\theta}2\bigg)\sigma_i\bigg(\!\cos\frac{\theta}2+i\scalar{\vsigma}{\axis}\sin\frac{\theta}2\bigg)=\\
		&=\cos^2\frac{\theta}2\sigma_i+\sin^2\frac{\theta}2(\scalar{\vsigma}{\axis}\sigma_i\scalar{\vsigma}{\axis})-i\sin\frac{\theta}2\cos\frac{\theta}2\scalar{\vsigma}{\axis}\sigma_i+i\sin\frac{\theta}2\cos\frac{\theta}2\sigma_i\scalar{\vsigma}{\axis}=\\
		&=\cos^2\frac{\theta}2\sigma_i+\sin^2\frac{\theta}2(\scalar{\vsigma}{\axis}\sigma_i\scalar{\vsigma}{\axis})+\frac{i}2\sin\theta[\sigma_i,\scalar{\vsigma}{\axis}].
	\end{split}
\end{equation}
Analizziamo a parte i due fattori con le matrici di Pauli:
\begin{equation}
	[\sigma_i,\scalar{\vsigma}{\axis}]=[\sigma_i,\sigma_kn_k]=n_k[\sigma_i,\sigma_k]=2i\epsilon_{ikj}n_k\sigma_j
\end{equation}
mentre
\begin{equation}
	\begin{split}
		\scalar{\vsigma}{\axis}\sigma_i\scalar{\vsigma}{\axis}&=[\scalar{\vsigma}{\axis},\sigma_i]\scalar{\vsigma}{\axis}+\sigma_i(\scalar{\vsigma}{\axis})^2=\\
		&=-2i\epsilon_{ikj}n_k\sigma_jn_l\sigma_l+\sigma_i=\\
		&=2i\epsilon_{ijk}n_kn_l(\delta_{jl}+i\epsilon_{jlp}\sigma_p)+\sigma_i=\\
		&=2i\epsilon_{ijk}n_kn_l\delta_{jl}-2\epsilon_{jki}\epsilon_{jls}n_kn_l\sigma_s+\sigma_i=\\
		&=2i\epsilon_{ijk}n_kn_j-2(\delta_{kl}\delta_{is}-\delta_{ks}\delta_{il})n_kn_l\sigma_s-\sigma_i=\\
		&=2n_kn_i\sigma_k-2n_kn_k\sigma_i+\sigma_i=\\
		&=2n_i\scalar{\vsigma}{\axis}-2\scalar{\axis}{\axis}\sigma_i+\sigma_i=\\
		&=2n_i\scalar{\vsigma}{\axis}-\sigma_i.
	\end{split}
\end{equation}
Con questi risulta allora
\begin{equation}
	\begin{split}
		U\sigma_i\adj{U}&=\cos^2\frac{\theta}2\sigma_i+\sin^2\frac{\theta}2(2n_i\scalar{\vsigma}{\axis}-\sigma_i)+\frac{i}2\sin\theta(2i\epsilon_{ikj}\sigma_jn_k)=\\
		&=\bigg(\!\cos^2\frac{\theta}2-\sin^2\frac{\theta}2\bigg)\sigma_i+2\sin^2\frac{\theta}2n_i\scalar{\vsigma}{\axis}-\sin\theta\epsilon_{ikj}n_k\sigma_j=\\
		&=\cos\theta\sigma_i+(1-\cos\theta)n_in_j\sigma_j-\sin\theta\epsilon_{ikj}n_k\sigma_j=\\
		&=\big[\cos\theta\delta_{ij}+(1-\cos\theta)n_in_j-\sin\theta\epsilon_{ikj}n_k\big]\sigma_j
	\end{split}
\end{equation}
per cui $P_{ji}=\cos\theta\delta_{ij}+(1-\cos\theta)n_in_j-\sin\theta\epsilon_{ikj}n_k$; applicato al vettore $x$ delle coordinate, si ha
\begin{equation}
	P_{ji}x_i=\cos\theta x_j-\sin\theta(x\times\axis)_j+(1-\cos\theta)(\scalar{x}{\axis})n_j
\end{equation}
Possiamo d'altronde scomporre $x$ in una parte parallela a $\axis$ e una ortogonale, scrivendo $x=x_\parallel+x_\perp$, dove $x_\parallel\defeq(\scalar{x}{\axis})\axis$ e $x_\perp\defeq x-(\scalar{x}{\axis})\axis$, e con questo si ha
\begin{equation}
	P_{ji}x_i=\cos\theta(x_\perp)_j+(x_\parallel)_j-\sin\theta(x_\perp\times\axis)_j,
\end{equation}
che mostra come la parte parallela rimane invariata, mentre la parte ortogonale è ruotata di $\theta$ nel piano ortogonale a $\axis$.
Scegliamo quindi, per esempio, $\axis=\vec e_3$: allora $n_jn_i=\delta_{ji}\delta_{i3}$, perch\'e vale 1 solo se $i=j=3$, e con questo
\begin{equation}
	P_{ji}=\cos\theta\delta_{ij}+\sin\theta\epsilon_{ji3}n_3+(1-\cos\theta)\delta_{ij}\delta_{j3}
\end{equation}
vale a dire
\begin{equation}
	P=
	\begin{pmatrix}
		\cos\theta	&-\sin\theta	&0\\
		\sin\theta	&\cos\theta		&0\\
		0			&0				&1
	\end{pmatrix}
\end{equation}
che è una matrice di $SO(3)$ per una rotazione attorno all'asse $\vec e_3$.
Allo stesso tempo, però, risulta
\begin{equation}
	U=\cos\frac{\theta}2-i\sigma_3\sin\frac{\theta}2=
	\begin{bmatrix}
		\cos\frac{\theta}2-i\sin\frac{\theta}2&0\\
		0&\cos\frac{\theta}2-i\sin\frac{\theta}2
	\end{bmatrix}
	=
	\begin{bmatrix}
		e^{i\theta/2}&0\\
		0&e^{i\theta/2}
	\end{bmatrix}.
\end{equation}
La differenza tra le due rappresentazioni è evidente, in quanto $P$ è periodica in $\theta$ di $2\pi$, mentre $U$ lo è di $4\pi$.
Questo mostra esplicitamente come, sebbene $\mathfrak{so}(3)\cong\mathfrak{su}(2)$, lo stesso non si può dire dei corrispondenti gruppi di Lie.
I gruppi $SO(3)$ e $SU(2)$ non possono cos\`i essere isomorfi, perch\'e non c'è una corrispondenza biunivoca tra i loro elementi: è sufficiente vedere che le due rotazioni di $2\pi$ e $4\pi$, che in $SU(2)$ sono differenti, in $SO(3)$ corrispondono allo stesso elemento, l'identità.
Più in generale, con la mappa $\rho$ che abbiamo costruito si nota che $U$ e $-U$ danno luogo alla medesima $\rho$.

\section{Momento angolare}
Come per le rotazioni $\Rot\in SO(3)$, definiamo il \emph{momento angolare} di un sistema quantistico come il generatore delle rotazioni.
Otterremmo cos\`i tre operatori che, come rappresentazione dell'algebra del gruppo delle rotazioni, soddisfano delle regole di commutazione analoghe alle parentesi di Lie di $\mathfrak{so}(3)$.
In realtà, siccome il momento angolare è un'osservabile, l'operatore ad esso associato deve essere hermitiano, perciò aggiustiamo un poco questa definizione.
La rappresentazione $\op U(\Rot)$ ``eredita'' la dipendenza da $\vtheta=\theta\axis$ della rotazione classica, quindi possiamo vederla direttamente come funzione $\op U=\op U(\vtheta)$.
Una rotazione di un angolo $\theta$ infinitesimo può essere approssimata linearmente come
\begin{equation}
	\op U(\vtheta)=1+\sum_{j=1}^3\drp{\op U}{\theta_j}\bigg|_{\vtheta=0}\theta_j+o(\theta)
\end{equation}
perciò definiamo i tre operatori del momento angolare come
\begin{equation}
	\op J_k\defeq i\hbar\drp{\op U}{\theta_k}\bigg|_{\vtheta=0}.
	\label{eq:def-momento-angolare}
\end{equation}
Come già visto per $\mathfrak{su}(2)$, i generatori di un gruppo di trasformazioni unitarie sono degli operatori antihermitiani, e il fattore $i$ nella definizione rende dunque i tre $\op J_k$ hermitiani; la costante $\hbar$ dà invece ad essi le dimensioni di un momento angolare.\footnote{
	Spesso si usa, per alleggerire la notazione, porre $\hbar=1$ per eliminarlo sistematicamente dalle equazioni.
	In tal caso si suppone di misurare il momento angolare (e le osservabili che ne derivano) in unità di $\hbar$.
	In pratica, il punto di partenza è dividere la \eqref{eq:commutazione-momento-angolare} per $\hbar^2$ ottenendo la forma più semplice $[\op L_i,\op L_j]=i\epsilon_{ijk}\op L_k$.
}
Questi tre operatori generano allora le rotazioni nel senso che, indicando $\op{\vec J}=(\op J_1,\op J_2,\op J_3)$,
\begin{equation}
	\op U(\axis,\theta)=\exp\bigg(\!-\frac{i}{\hbar}\theta\scalar{\axis}{\op{\vec J}}\bigg).
\end{equation}

\paragraph{Rotazione di operatori}
Ora che è definito il momento angolare, vale la pena ritornare sulla rotazione degli operatori vista nell'equazione \eqref{eq:rotazione-operatore}.
Per una trasformazione vicina all'identità, ossia una rotazione di un angolo $\theta$ infinitesimo (attorno a un generico asse dato da $\axis$), possiamo approssimare
\begin{equation}
	\op U(\axis,\theta)\approx 1-\frac{i}{\hbar}\theta n_k\op J_k
	\qeq
	\Rot(\axis,\theta)_{ij}\approx(1+\theta n_k\Ang_k)_{ij}=\delta_{ij}+\theta n_k(\Ang_k)_{ij}=\delta_{ij}+\theta n_k\epsilon_{ijk}.
\end{equation}
Per un operatore vettoriale $\op{\vec a}=(\op a_1,\op a_2,\op a_3)$ la \eqref{eq:rotazione-operatore} si scrive dunque come
\begin{equation}
	\begin{aligned}
		\bigg(1-\frac{i}{\hbar}\theta n_k\op J_k\bigg)\op a_i\bigg(1+\frac{i}{\hbar}\theta n_k\op J_k\bigg)&=(1+\theta n_k\Ang_k)_{ij}\op a_j\\
		\op a_i-\frac{i}{\hbar}\theta n_k\op J_k\op a_i+\frac{i}{\hbar}\theta n_k\op a_i\op J_k+\frac1{\hbar^2}\theta^2n_k\op J_k\op a_in_k\op J_k&=(\delta_{ij}+\theta n_k\epsilon_{ijk})\op a_j\\
		\op a_i-\frac{i}{\hbar}\theta n_k\op J_k\op a_i+\frac{i}{\hbar}\theta n_k\op a_i\op J_k&=\op a_i+\theta\epsilon_{ijk}n_k\op a_j\\
		-\frac{i}{\hbar}\theta[n_k\op J_k,\op a_i]&=\theta\epsilon_{ijk}n_k\op a_j\\
		[n_k\op J_k,\op a_i]&=i\hbar\epsilon_{ijk}n_k\op a_j
	\end{aligned}
\end{equation}
in cui abbiamo trascurato il termine con $\theta^2$ in quanto $o(\theta)$, dato che stiamo approssimando al primo ordine.
Scegliendo ora per $\axis$ i tre assi cartesiani, con $(\vec e_l)_k=\delta_{lk}$, si ha allora
\begin{equation}
	[\delta_{lk}\op J_k,\op a_i]=i\hbar\epsilon_{ijk}\delta_{lk}\op a_j
	\qqq
	[\op J_l,\op a_i]=i\hbar\epsilon_{ijl}\op a_j
\end{equation}
la quale, rinominando gli indici, assume la forma più familiare
\begin{equation}
	[\op J_i,\op a_j]=i\hbar\epsilon_{ijk}\op a_k
	\label{eq:rotazione-operatori-vettoriali-commutatore}
\end{equation}
che dunque caratterizza la rotazione degli operatori vettoriali.
In particolare, lo stesso momento angolare soddisfa questa relazione, poich\'e segue le stesse regole di commutazione dell'algebra $\mathfrak{so}(3)$, vale a dire\footnote{
	Più precisamente, i commutatori delle componenti del momento angolare contengono il termine $i\hbar\epsilon_{ijk}$, che differisce dalle costanti di struttura $\epsilon_{ijk}$ che definiscono l'algebra $\mathfrak{so}(3)$ per la costante $i\hbar$.
	Ricordiamo però che questa costante è proprio quella per cui abbiamo moltiplicato i generatori delle rotazioni in modo che ``apparissero'' hermitiani e con le dimensioni fisiche adatte, quindi questa differenza è ben giustificata.
}
\begin{equation}
	[\op J_i,\op J_j]=i\hbar\epsilon_{ijk}\op J_k.
	\label{eq:commutazione-momento-angolare}
\end{equation}

Insieme alle tre componenti cartesiane del momento angolare abbiamo anche il quadrato del suo modulo, ossia $\op{\vec J}^2=\op J_i\op J_i$: essendo uno scalare, ci aspettiamo che sia invariante per rotazioni ossia che commuti con tutte le componenti del momento angolare.
Una verifica diretta mostra infatti che, per $i=1,2,3$,
\begin{equation}
	[\op{\vec J}^2,\op J_i]=[\op J_k\op J_k,\op J_i]=\op J_k[\op J_k,\op J_i]+[\op J_k,\op J_i]\op J_k=i\hbar\epsilon_{kil}(\op J_k\op J_l+\op J_l\op J_k)=i\hbar(\epsilon_{kil}+\epsilon_{lik})\op J_k\op J_l=0
\end{equation}
per l'antisimmetria di $\epsilon_{kil}$.
In ogni caso le tre componenti $\op J_i$ non sono tra loro compatibili (dalla \eqref{eq:commutazione-momento-angolare}) a meno del caso banale in cui siano tutte nulle.
Nella costruzione di un sistema completo di osservabili compatibili, è convenzione scegliere insieme a $\op{\vec J}^2$ anche la componente $z$, ossia $\op J_3$, da diagonalizzare simultaneamente.

\section{Autovalori del momento angolare} \label{sec:autovalori-momento-angolare}
Supponiamo di aver trovato un sistema completo di osservabili compatibili che contenga $\op{\vec J}^2$ e $\op J^3$.
Chiamiamo $m\hbar$ gli autovalori di $\op J_3$ e $\mu^2\hbar^2$ quelli di $\op{\vec J}^2$, e trascurando lo altre osservabili del sistema indichiamo gli autostati simultanei con $\ket{m,\mu^2}$, che sono quindi tali per cui\footnote{Gli autovalori di $\op{\vec J}^2$ sono evidentemente positivi, perciò li indichiamo direttamente con il quadrato $\mu^2$.}
\begin{equation}
	\op{\vec J}^2\ket{m,\mu^2}=\mu^2\hbar^2\ket{m,\mu^2}
	\hspace{1cm}\text{e}\hspace{1cm}
	\op J_3\ket{m,\mu^2}=m\hbar\ket{m,\mu^2}.
\end{equation}
Come già per l'oscillatore armonico, introduciamo gli operatori a scala $\op J_+\defeq\op J_1+i\op J_2$ e $\op J_-\defeq\op J_1-i\op J_2$.
Dato che gli $\op J_i$ sono hermitiani (poich\'e rappresentano delle osservabili) si vede subito che $\adj{\op J_+}=\op J_-$.
Essi sono in relazione con la componente scelta del momento angolare con i commutatori
\begin{equation}
	[\op J_3,\op J_+]=[\op J_3,\op J_1]+i[\op J_3,\op J_2]=\hbar(i\op J_2-i^2\op J_1)=\hbar\op J_+
\end{equation}
da cui
\begin{equation}
	[\op J_3,\op J_-]=[\op J_3,\adj{\op J_+}]=-\adj{[\op J_3,\op J_+]}=-\hbar\adj{\op J_+}=-\hbar\op J_-.
\end{equation}
Vediamo dunque come questi due operatori agiscono sugli autostati:
\begin{multline}
	\op J_3\op J_+\ket{m,\mu^2}=
	(\op J_3\op J_+ - \op J_+\op J_3 + \op J_+\op J_3)\ket{m,\mu^2}=
	[\op J_3,\op J_+]\ket{m,\mu^2}+\op J_+\op J_3\ket{m,\mu^2}=\\=
	\hbar\op J_+\ket{m,\mu^2}+m\hbar\op J_+\ket{m,\mu^2}=
	(m+1)\hbar\op J_+\ket{m,\mu^2}
\end{multline}
e analogamente $\op J_3\op J_-\ket{m,\mu^2}=(m-1)\hbar\op J_-\ket{m,\mu^2}$.
Gli operatori $\op J_+$ e $\op J_-$ dunque portano un autostato di $\op J_3$ in un altro autostato con autovalore, rispettivamente, aumentato o diminuito di $\hbar$.
Più brevemente scriviamo che $\op J_+\ket{m,\mu^2}=\ket{m+1,\mu^2}$ e $\op J_-\ket{m,\mu^2}=\ket{m-1,\mu^2}$.

Dobbiamo quindi chiederci se la sequenza $\{\dots,m-2,m-1,m,m+1,\dots\}$ sia limitata o meno.
Dato che $\op J_3^2=\op{\vec J}^2-\op J_1^2+\op J_2^2$, sicuramente per ciascuno stato il valore di aspettazione di $\op J_3^2$ deve essere minore di quello di $\op{\vec J}^2$, dato che ovviamente $\op J_1^2+\op J_2^2$ è un operatore definito positivo.
In particolare, dunque, risulta $m^2\le\mu^2$, ossia $\abs{m}\le\abs{\mu}$: gli autovalori sono allora necessariamente limitati; esiste un certo stato che chiamiamo $\ket{j_+,\mu^2}$ tale per cui $\op J_+\ket{j_+,\mu^2}=0$ e analogamente uno stato $\ket{j_-,\mu^2}$ per cui $\op J_-\ket{j_-,\mu^2}=0$, dove $j_+$ e $j_-$ sono il massimo e il minimo autovalore, rispettivamente, di $\op J_3$.
Per questi due stati si ha comunque $\op{\vec J}^2\ket{j_\pm,\mu^2}=\mu^2\hbar^2\ket{j_\pm,\mu^2}$.
Calcolando la norma di $\op J_+\ket{j_+,\mu^2}$ troviamo
\begin{equation}
	\begin{split}
		0&=\bra{j_+,\mu^2}\adj{\op J_+}\op J_+\ket{j_+,\mu^2}=\\
		&=\bra{j_+,\mu^2}\op J_-\op J_+\ket{j_+,\mu^2}=\\
		&=\bra{j_+,\mu^2}(\op J_1-i\op J_2)(\op J_1+i\op J_2)\ket{j_+,\mu^2}=\\
		&=\bra{j_+,\mu^2}(\op J_1^2+\op J_2^2+i[\op J_1,\op J_2])\ket{j_+,\mu^2}=\\
		&=\bra{j_+,\mu^2}(\op{\vec J}^2-\op J_3^2-\hbar\op J_3)\ket{j_+,\mu^2}=\\
		&=(\mu^2-j_+^2-j_+)\hbar^2\braket{j_+,\mu^2}{j_+,\mu^2}
	\end{split}
\end{equation}
da cui otteniamo $\mu^2=j_+(j_++1)$.
Dalla norma di $\op J_-\ket{j_-,\mu^2}$, anch'essa nulla, troviamo invece $\mu^2=j_-(j_--1)$.
Assegnato un valore a $j_-$, uguagliando le due espressioni abbiamo $j_+(j_++1)=j_-(j_--1)$ da cui $j_+=-j_-$ oppure $j_+=j_--1$.
La seconda delle due però non è accettabile dato che per costruzione $j_+\ge j_-$, perciò rimane $j_+=-j_-$.
Chiamiamo questo valore semplicemente con $j$.
Abbiamo quindi ottenuto lo spettro di $\op J_3$ che è l'insieme $\{-j\hbar,(-j+1)\hbar,\dots,(j-1)\hbar,j\hbar\}$, che ha $2j+1$ elementi.
Questa cardinalità è chiaramente un numero intero, perciò $j$ deve essere a sua volta intero oppure semiintero (positivo o nullo).
Una volta che $\op J_3$ assume uno di questi valori, poi, $\op{\vec J}^2$ ha come autovalore $j(j+1)\hbar^2$: tale numero non è un quadrato perfetto, per il fatto che anche quando $j=m$ (per il massimo autovalore di $\op J_3$) non si ha comunque $\mu^2=m^2$, perch\'e da questo seguirebbe che $\op J_1$ e $\op J_2$ avrebbero solo autovalori nulli, ossia il momento angolare lungo i due assi restanti sarebbe nullo; sappiamo che questo non è possibile, perch\'e non possiamo determinare con precisione assoluta contemporaneamente due componenti del momento angolare.
L'unica eccezione a questo si ha nel caso banale in cui $j=0$, in cui $\op{\vec J}=0$.

In questa rappresentazione del momento angolare, inoltre, $\op{\vec J}^2$ è un multiplo dell'identità (detto anche \emph{operatore di Casimir}): è degenere dato che ad ogni suo autostato corrispondono $2j+1$ autostati linearmente indipendenti (di $\op J_3$), come si poteva anche capire dal teorema \ref{t:degenerazione} oppure dal lemma di Schur.
La rappresentazione è inoltre determinata completamente determinata dal numero $j$.\footnote{Ogni rappresentazione del gruppo delle rotazioni è univocamente determinata da un numero intero o semiintero positivo o nullo. Tutte le rappresentazioni irriducibili si ottengono in questo modo, mentre quelle riducibili si ricavano come somma diretta o prodotto di queste.}
Ad esempio la rappresentazione con $j=\frac12$ è data dalle matrici di Pauli: si ha infatti $\sigma_3=\frac12\begin{psmallmatrix}1&0\\0&-1\end{psmallmatrix}$ e $\frac14(\sigma_1^2+\sigma_2^2+\sigma_3^2)=\frac34=j(j+1)$ che corrisponde a $\op{\vec J}^2$.

\section{Momento angolare orbitale}
Possiamo definire l'operatore del momento angolare \emph{orbitale} di una particella attorno all'origine, in coordinate cartesiane, utilizzando la definizione classica e sostituendo gli operatori corrispondenti: otteniamo
\begin{equation}
	\op L_k=\epsilon_{ijk}\op x_i\op p_j
	\label{eq:momento-angolare-orbitale}
\end{equation}
in dimensione 3.
Si può eventualmente generalizzare a un numero differente di dimensioni seguendo le regole di commutazione dell'algebra $\mathfrak{so}(n)$.
Nella rappresentazione di Schr\"odinger della posizione troviamo che $\op L_i$ è dato da
\begin{equation}
	L_i=\epsilon_{ijk}x_j\bigg(-i\hbar\drp{}{x_k}\bigg)=-i\hbar\epsilon_{ijk}x_j\drp{}{x_k}.
\end{equation}
Possiamo ottenere però una rappresentazione più vantaggiosa usando le coordinate polari, più adatte a descrivere ad esempio sistemi a simmetria centrale, cioè invarianti per rotazioni.
Usiamo la trasformazione
\begin{equation}
	\begin{pmatrix}
		x_1\\
		x_2\\
		x_3
	\end{pmatrix}
	=
	\begin{pmatrix}
		r\sin\theta\cos\phi\\
		r\sin\theta\sin\phi\\
		r\cos\theta
	\end{pmatrix}:
\end{equation}
le tre componenti del momento angolare orbitale, in rappresentazione di Schr\"odinger negli autostati della posizione, sono
\begin{equation}
	\begin{split}
		L_1=&-i\hbar\bigg(x_2\drp{}{x_3}-x_3\drp{}{x_2}\bigg)=\\
		=&-i\hbar\bigg[x_2\bigg(\drp{r}{x_3}\drp{}{r}+\drp{\theta}{x_3}\drp{}{\theta}+\drp{\phi}{x_3}\drp{}{\phi}\bigg)
			-x_3\bigg(\drp{r}{x_2}\drp{}{r}+\drp{\theta}{x_2}\drp{}{\theta}+\drp{\phi}{x_2}\drp{}{\phi}\bigg)\bigg]=\\
		=&-i\hbar\bigg[r\sin\theta\sin\phi\bigg(\!\!\cos\theta\drp{}{r}-\frac{\sin\theta}{r}\drp{}{\theta}\bigg)
			-r\cos\theta\bigg(\!\!\sin\theta\sin\phi\drp{}{r}+\frac{\cos\theta\sin\phi}{r}\drp{}{\theta}+\frac{\cos\phi}{r\sin\theta}\drp{}{\phi}\bigg)\bigg]=\\
		=&-i\hbar\bigg(r\cos\theta\sin\theta\sin\phi\drp{}{r}-\sin^2\theta\sin\phi\drp{}{\theta}-r\cos\theta\sin\theta\sin\phi\drp{}{r}+\\
			&+\cos^2\theta\sin\phi\drp{}{\theta}-\cot\theta\cos\phi\drp{}{\phi}\bigg)=\\
		=&\,i\hbar\bigg(\!\sin\phi\drp{}{\theta}+\cot\theta\cos\phi\drp{}{\phi}\bigg);
	\end{split}
	\label{eq:L_1-schroedinger}
\end{equation}
\begin{equation}
	\begin{split}
		L_2=&-i\hbar\bigg(x_3\drp{}{x_1}-x_1\drp{}{x_3}\bigg)=\\
		=&-i\hbar\bigg(r\cos\theta\sin\theta\cos\phi\drp{}{r}-\cot\theta\sin\phi\drp{}{\phi}+\cos^2\theta\cos\phi\drp{}{\theta}-r\cos\theta\sin\theta\cos\phi\drp{}{r}+\\
			&+\sin^2\theta\cos\phi\drp{}{\theta}\bigg)=\\
		=&-i\hbar\bigg(\!\cos\phi\drp{}{\theta}-\cot\theta\sin\phi\drp{}{\phi}\bigg);
	\end{split}
	\label{eq:L_2-schroedinger}
\end{equation}
\begin{equation}
	\begin{split}
		L_3=&-i\hbar\bigg(x_1\drp{}{x_2}-x_2\drp{}{x_1}\bigg)=\\
		=&-i\hbar\bigg[r\cos\phi\sin\phi\sin^2\theta\drp{}{r}+\cos\theta\sin\theta\cos\phi\sin\phi\drp{}{\theta}+\cos^2\phi\drp{}{\phi}-r\cos\phi\sin\phi\sin^2\theta\drp{}{r}-\\
			&-\cos\theta\sin\theta\cos\phi\sin\phi\drp{}{\theta}+\sin^2\theta\drp{}{\phi}\bigg]=\\
		=&-i\hbar\drp{}{\phi}.
	\end{split}
	\label{eq:L_3-schroedinger}
\end{equation}
Da questi otteniamo gli operatori a scala
\begin{equation}
	\begin{split}
		L_+&=L_1+iL_2=i\hbar\bigg(\!\sin\phi\drp{}{\theta}+\cot\theta\cos\phi\drp{}{\phi}\bigg)+\hbar\bigg(\!\cos\phi\drp{}{\theta}-\cot\theta\sin\phi\drp{}{\phi}\bigg)=\\
		&=\hbar\bigg[(i\sin\phi+\cos\phi)\drp{}{\theta}+(i\cos\phi-\sin\phi)\cot\theta\drp{}{\phi}\bigg]=\\
		&=\hbar e^{i\phi}\bigg(\drp{}{\theta}+i\cot\theta\drp{}{\phi}\bigg)
	\end{split}
	\label{eq:L_+-schroedinger}
\end{equation}
e in modo analogo
\begin{equation}
	L_-=L_1-iL_2=\hbar e^{-i\phi}\bigg(\!-\drp{}{\theta}+i\cot\theta\drp{}{\phi}\bigg).
	\label{eq:L_--schroedinger}
\end{equation}
Con queste espressioni possiamo infine rappresentare anche $\op{\vec L}^2$, ricordando che è uguale a $\op L_+\op L_-+\op L_3^2-\hbar\op L_3$: siccome
\begin{equation}
	L_+L_-=-\hbar^2\bigg(\ddrp{}{\theta}+\cot\theta\drp{}{\theta}+\cot^2\theta\ddrp{}{\phi}+i\drp{}{\phi}\bigg)
\end{equation}
troviamo che
\begin{equation}
	\begin{split}
		\vec L^2&=-\hbar^2\bigg(\ddrp{}{\theta}+\cot\theta\drp{}{\theta}+\cot^2\theta\ddrp{}{\phi}+i\drp{}{\phi}+\ddrp{}{\phi}-i\drp{}{\phi}\bigg)=\\
		&=-\hbar^2\bigg(\ddrp{}{\theta}+\cot\theta\drp{}{\theta}+\frac1{\sin^2\theta}\ddrp{}{\phi}\bigg)=\\
		&=-\hbar^2\bigg[\frac1{\sin\theta}\bigg(\!\sin\theta\ddrp{}{\theta}+\cos\theta\drp{}{\theta}\bigg)+\frac1{\sin^2\theta}\ddrp{}{\phi}\bigg]=\\
		&=-\hbar^2\bigg[\frac1{\sin\theta}\drp{}{\theta}\bigg(\!\sin\drp{}{\theta}\bigg)+\frac1{\sin^2\theta}\ddrp{}{\phi}\bigg]
	\end{split}
	\label{eq:L^2-schroedinger}
\end{equation}
e il termine tra le parentesi quadre, a meno del fattore $1/r^2$, è la parte angolare del laplaciano in coordinate sferiche.

\paragraph{Il momento angolare orbitale in dimensione generica}
Possiamo sfruttare un approccio alternativo per ricavare la rappresentazione di Schr\"odinger di $\op{\vec L}^2$, senza passare per le coordinate sferiche e tutti i conti fatti precedentemente.
Se in dimensione 3 il momento angolare orbitale si può definire tramite la \eqref{eq:momento-angolare-orbitale}, in una dimensione $d$ generica si può definire il tensore
\begin{equation}
	L_{ij}=x_ip_j-x_jp_i
	\label{eq:tensore-momento-angolare}
\end{equation}
che è un tensore antisimmetrico di rango 2.
Da esso possiamo risalire al classico vettore $\vec L$ contraendolo con la $\epsilon_{ijk}$: risulta infatti
\begin{equation}
	\epsilon_{ijk}L_{ij}=\epsilon_{ijk}(x_ip_j-x_jp_i)=\epsilon_{ijk}x_ip_j+\epsilon_{jik}x_jp_i=2L_k
\end{equation}
dunque $L_k=\frac12\epsilon_{ijk}L_{ij}$.
Viceversa, si controlla facilmente che $\epsilon_{ijk}L_k=L_{ij}$.\footnote{
	Queste relazioni hanno una valenza più generale, con il concetto di \emph{tensore duale}: un tensore antisimmetrico $A$ di rango $k$ può essere sempre mappato in un tensore sempre antisimmetrico di rango $k-d$ tramite il simbolo di Levi-Civita $d$-dimensionale, cioè
	\begin{equation}
		A_{i_1,\dots,i_k}\mapsto A^*_{i_{k+1},\dots,i_d}=\frac1{k!}\epsilon_{i_1,\dots,i_d}A_{i_1,\dots,i_k}
		\label{eq:tensore-duale}
	\end{equation}
	e il tensore $A^*$ è detto \emph{duale} di $A$.
	La definizione si inverte nel modo
	\begin{equation}
		A_{i_1,\dots,i_k}=\frac1{(d-k)!}\epsilon_{i_1,\dots,i_k,i_{k+1},\dots,i_d}A^*_{i_{k+1},\dots,i_d}.
		\label{eq:tensore-duale-inversione}
	\end{equation}
	Con questa definizione ad ogni vettore $\vec v\in\R^3$, che è un tensore di rango 1, è possibile associare un tensore antisimmetrico di rango 2 dato da $v^*_{ij}=\epsilon_{ijk}v_k$.
}
Tutti questi risultati potranno essere presi in dimensione generica, dato che non è mai stata specificata in questi calcoli.
Troviamo inoltre le relazioni
\begin{equation}
	\begin{split}
		[L_i,L_j]&=\epsilon_{lmi}\epsilon_{ksj}[x_lp_m,x_kp_s]=\\
		&=i\hbar\epsilon_{lmi}\epsilon_{ksj}(\delta_{ls}x_kp_m-\delta_{mk}x_lp_s)=\\
		&=i\hbar(\epsilon_{lmi}\epsilon_{klj}x_kp_m-\epsilon_{lki}\epsilon_{ksj}x_lp_s)=\\
		&=i\hbar\big[(\delta_{mj}\delta_{ik}-\delta_{mk}\delta_{ij})x_kp_m-(\delta_{is}\delta_{lj}-\delta_{ls}\delta_{ij})x_lp_s\big]=\\
		&=i\hbar(x_ip_j-x_jp_i)=\\
		&=i\hbar L_{ij};\\
		[L_{ij},L_{mn}]&=[x_ip_j,x_mp_n]-[x_ip_j,x_np_m]-[x_jp_i,x_mp_n]+[x_jp_i,x_np_m]=\\
		&=i\hbar(-\delta_{jm}x_ip_n+\delta_{in}x_mp_j+\delta_{jn}x_ip_m-\delta_{im}x_np_j+\delta_{im}x_jp_n-\delta_{jn}x_mp_i-\delta_{in}x_jp_m+\delta_{jm}x_np_i)=\\
		&=i\hbar\big[\delta_{jm}(-x_ip_n+x_np_i)+\delta_{in}(x_mp_j-x_jp_m)+\delta_{jn}(x_ip_m-x_mp_i)+\delta_{im}(-x_np_j+x_jp_n)\big]=\\
		&=i\hbar(\delta_{jm}L_{ni}+\delta_{jn}L_{im}+\delta_{im}L_{jn}+\delta_{in}L_{mj}).
	\end{split}
\end{equation}
La norma al quadrato del momento angolare orbitale può essere quindi riscritta con il tensore $L_{ij}$ come
\begin{multline}
	\vec L^2=\delta_{ij}L_iL_j=\frac14\delta_{ij}\epsilon_{kli}L_{kl}\epsilon_{mnj}L_{mn}=\frac14\epsilon_{ikl}\epsilon_{imn}L_{kl}L_{mn}=\\
	=\frac14(\delta_{km}\delta_{ln}-\delta_{lm}\delta_{kn})L_{kl}L_{mn}=\frac14(L_{kl}L_{kl}-L_{kl}L_{lk})=\frac12L_{kl}L_{kl}.
\end{multline}
Al tensore $L_{ij}$ esso possiamo associare come al solito l'operatore $\op L_{ij}$ sostituendo opportunamente gli operatori di posizione e impulso.
Dall'ultima equazione otteniamo allora un'espressione per $\op{\vec L}^2$:
\begin{equation}
	\begin{split}
		\op{\vec L}^2&=\frac12\op L_{ij}\op L_{ij}=\frac12(\op x_i\op p_j-\op x_j\op p_i)(\op x_i\op p_j-\op x_j\op p_i)=\\
		&=\frac12(\op x_i\op p_j\op x_i\op p_j-\op x_i\op p_j\op x_j\op p_i-\op x_j\op p_i\op x_i\op p_j+\op x_j\op p_i\op x_j\op p_i)=\\
		&=\frac12\big[\op x_i(\op x_i\op p_j-i\hbar\delta_{ij})\op p_j-\op x_i(\op x_j\op p_j-i\hbar\delta_{jj})\op p_i-\op x_j(\op x_i\op p_i-i\hbar\delta_{ii})\op p_j+\op x_j(\op x_j\op p_i-i\hbar\delta_{ij})\op p_i\big]=\\
	&=\op{\vec x}^2\op{\vec p}^2+i\hbar(d-1)\scalar{\op{\vec x}}{\op{\vec p}}-\frac12\big[\op x_i(\scalar{\op{\vec x}}{\op{\vec p}})\op p_i+\op x_j(\scalar{\op{\vec x}}{\op{\vec p}})\op p_j\big]=\\
	&=\op{\vec x}^2\op{\vec p}^2+i\hbar(d-1)\scalar{\op{\vec x}}{\op{\vec p}}-\frac12\big[\op x_i\op p_i(\scalar{\op{\vec x}}{\op{\vec p}})-i\hbar \op x_i\op p_i+\op x_j\op p_j(\scalar{\op{\vec x}}{\op{\vec p}})-i\hbar \op x_j\op p_j\big]=\\
		&=\op{\vec x}^2\op{\vec p}^2+i\hbar(d-1)\scalar{\op{\vec x}}{\op{\vec p}}-(\scalar{\op{\vec x}}{\op{\vec p}})^2-i\hbar\scalar{\op{\vec x}}{\op{\vec p}}=\\
		&=\op{\vec x}^2\op{\vec p}^2+i\hbar(d-2)\scalar{\op{\vec x}}{\op{\vec p}}-(\scalar{\op{\vec x}}{\op{\vec p}})^2.
	\end{split}
	\label{eq:L^2-dimensione-generica}
\end{equation}
In particolare in tre dimensioni abbiamo $\op{\vec L}^2=\op{\vec x}^2\op{\vec p}^2+i\hbar\scalar{\op{\vec x}}{\op{\vec p}}-(\scalar{\op{\vec x}}{\op{\vec p}})^2$.
Passiamo ora alla rappresentazione di Schr\"odinger (per funzioni in $\leb[2]{\R^d}$, essendo la dimensione generica) in coordinate polari.
Dalla \eqref{eq:L^2-dimensione-generica} possiamo ricavare un'espressione per $\op{\vec p}^2$ in coordinate polari: è sufficiente moltiplicare a sinistra per l'operatore $\op{\vec x}^{-2}$ (l'inverso del quadrato della norma).
Nella rappresentazione di Schr\"odinger delle coordinate, $\op{\vec x}$ è diagonale, e in coordinate sferiche possiamo definire l'operatore
\begin{equation}
	\op r\defeq\bigg(\sum_{i=1}^d\op x_i^2\bigg)^2
	\label{eq:operatore-raggio}
\end{equation}
che fornisce la distanza dall'origine ed è evidentemente autoaggiunto.
Dal termine
\begin{equation}
	\scalar{\op{\vec x}}{\op{\vec p}}=-i\hbar x_i\drp{}{x_i}=-i\hbar r\frac{x_i}{r}\drp{}{x_i}=-i\hbar r\drp{r}{x_i}\drp{}{x_i}=-i\hbar r\drp{}{r}
\end{equation}
siamo indotti a definire anche l'operatore coniugato a $\op r$, che è l'impulso radiale $\op p_r$ rappresentato in $\leb[2]{\R^d}$ nelle coordinate sferiche da $-i\hbar\drp{}{r}$, in modo che $\scalar{\op{\vec x}}{\op{\vec p}}=\op r\op p_r$.
Questo operatore però non è necessariamente autoaggiunto: se per verificarlo nel casi dei $\op p_i$ cartesiani era sufficiente integrare per parti, dato che i termini al contorno (per $\abs{x}\to+\infty$) erano nulli, in questo caso il bordo del dominio di $r$ è $0$ e $+\infty$, e non c'è alcun motivo di supporre che le funzioni d'onda siano nulle nell'origine; oltretutto, la misura in coordinate polari non è il semplice prodotto dei $\dd x_i$ ma contiene altri fattori.
Con queste definizioni abbiamo dunque
\begin{equation}
	(\scalar{\op{\vec x}}{\op{\vec p}})^2=-\hbar^2r\drp{}{r}\bigg(r\drp{}{r}\bigg)=-\hbar^2\bigg(r\drp{}{r}+r^2\ddrp{}{r}\bigg)=\op r^2\op p_r^2-i\hbar \op r\op p_r
\end{equation}
e il quadrato dell'impulso si rappresenta allora come
\begin{equation}
	\op{\vec p}^2=-\hbar^2\ddrp{}{r}-\hbar^2(d-1)\frac1{r}\drp{}{r}+\frac{L^2}{r^2}=
	-\hbar^2\bigg[\ddrp{}{r}+\frac{(d-1)}{r}\drp{}{r}\bigg]+\frac{L^2}{r^2}
	\label{eq:rappresentazione-impulso-coordinate-sferiche}
\end{equation}
dove $L$ è un opportuno operatore di $\leb[2]{\R^d}$ che rappresenta il momento angolare orbitale.
Notiamo infine che il termine tra parentesi quadre è il termine radiale del laplaciano in dimensione $d$, che è
\begin{equation}
	\frac{d-1}{r}\drp{}{r}+\ddrp{}{r}=\frac1{r^{d-1}}\bigg[(d-1)r^{d-2}\drp{}{r}+r^{d-1}\ddrp{}{r}\bigg]=\frac1{r^{d-1}}\drp{}{r}\bigg(r^{d-1}\drp{}{r}\bigg).
	\label{eq:laplaciano-dimensione-generica}
\end{equation}

Torniamo ora al problema degli autovalori.
Affinch\'e la funzione d'onda sia continua, deve risultare periodica di $2\pi$ nella variabile $\phi$.
Cos\`i come una funzione definita su un intervallo limitato si può analizzare in serie di Fourier e ammette dei modi normali di oscillazione con un insieme discreto (numerabile) di frequenze, anche la parte in $\phi$ delle autofunzioni di $\op L_3$ avrà questa caratteristica: questo porta, tra le altre cose, alla quantizzazione del momento angolare.
Le autofunzioni di questo operatore sono infatti funzioni $f(r,\phi,\theta)$ tali che
\begin{equation}
	-i\hbar\drp{f}{\phi}(r,\phi,\theta)=m\hbar f(r,\phi,\theta)\qqq f(r,\phi,\theta)=g(r,\theta)e^{im\phi}.
\end{equation}
Imponendo la periodicità della funzione otteniamo che deve soddisfare
\begin{equation}
	g(r,\theta)e^{im\phi}=f(r,\theta,\phi+2\pi)=g(r,\theta)e^{im(\phi+2\pi)}=g(r,\theta)e^{im\phi}e^{2im\pi}
\end{equation}
da cui ricaviamo che $m$ deve essere intero in modo che $e^{2im\pi}=1$.

Un operatore hamiltoniano della forma $\frac1{2m}\op{\vec p}^2+V(\norm{\op{\vec x}}^2)$ è invariante per rotazioni e commuta dunque con $\op{\vec L}^2$ e $\op L_3$.
In generale sarà un operatore degenere: possiamo etichettare gli autostati con tre numeri $E,l,m$ tali che, oltre all'equazione di Schr\"odinger, abbiamo
\begin{equation}
	L^2\psi_{E,l,m}(\vec x)=l(l+1)\hbar^2\psi_{E,l,m}(\vec x)\qeq L_3\psi_{E,l,m}(\vec x)=m\hbar\psi_{E,l,m}(\vec x).
	\label{eq:autofunzioni-momento-angolare}
\end{equation}
Notiamo che nelle equazioni agli autovalori \eqref{eq:autofunzioni-momento-angolare} per le funzioni $\psi_{E,l,m}$ non sono coinvolti il potenziale e l'energia del sistema, ma solo i numeri $l$ e $m$.

Per cercare le autofunzioni scegliamo innanzitutto un potenziale nullo, ottenendo l'equazione $-\hbar^2\lap\psi=2mE\psi$.
Ponendo $k^2\defeq\frac{2mE}{\hbar^2}$ possiamo semplificarla nella forma $\lap\psi=-k^2\psi$.
Effettuiamo dunque una separazione delle variabili fattorizzando la funzione d'onda come $R(r)Y(\phi,\theta)$: nella prima delle \eqref{eq:autofunzioni-momento-angolare} troviamo cos\`i $L^2R(r)Y(\phi,\theta)=\hbar^2l(l+1)R(r)Y(\phi,\theta)$ in cui semplifichiamo $R(r)$ trovando
\begin{equation}
	L^2Y(\phi,\theta)=\hbar^2l(l+1)Y(\phi,\theta)
\end{equation}
e con un ragionamento analogo, detto $g(l)$ l'autovalore di $L^2$ in dimensione generica $d$, l'equazione $\lap\psi=-k^2\psi$ si riscrive con la \eqref{eq:rappresentazione-impulso-coordinate-sferiche} come
\begin{equation}
	Y(\phi,\theta)\bigg[\frac1{r^{d-1}}\drp{}{r}r^{d-1}\drp{}{r}+\frac{g(l)}{r^2}\bigg]R(r)=-k^2R(r)Y(\phi,\theta)
	\label{eq:laplace-parte-radiale}
\end{equation}
e possiamo semplificare il fattore $Y(\phi,\theta)$ dai due membri.
Ora possiamo porre anche $E=0$, ottenendo per la funzione d'onda l'equazione di Laplace $\lap\psi=0$: essa è tale che se $\psi(\vec x)$ è soluzione, lo è anche $\psi(\lambda\vec x)$ per ogni $\lambda\in\R$, ossia le soluzioni sono funzioni omogenee.
Cercheremo le soluzioni a questa equazione, quindi, nell'insieme dei polinomi omogenei.

\paragraph{Equazione di Laplace in $\R^2$}
Data l'equazione $\lap u(x,y)=0$, sfruttiamo l'isomorfismo tra $\R^2$ e $\C$ per semplificare le operazioni, con il cambio di coordinate
\begin{equation}
	x=\frac{\eta+\eta^*}2\qeq y=\frac{\eta-\eta^*}{2i}
\end{equation}
ossia ponendo $\eta\defeq x+iy$.
L'operatore laplaciano si riscrive come
\begin{equation}
	\ddrp{}{x}+\ddrp{}{y}=4\frac{\partial^2}{\partial\eta\partial\eta^*}
\end{equation}
per cui l'equazione di Laplace diventa $\frac{\partial^2}{\partial\eta\partial\eta^*}u(\eta,\eta^*)=0$.
Se ora $u$ è una funzione olomorfa, non dipende da $\eta^*$ quindi è evidentemente soluzione dell'equazione; analogamente se è antiolomorfa, ossia non dipende da $\eta$.
L'equazione $\lap u=0$ è inoltre invariante per trasformazioni conformi, ossia mappe $\C\to\C$ olomorfe.
In ogni caso, prendiamo un generico polinomio in $\eta$ e $\eta^*$ omogeneo di grado $l$
\begin{equation}
	u_l(\eta,\eta^*)=\sum_{p=0}^lc_p\eta^p(\eta^*)^{l-p}:
\end{equation}
affinch\'e sia soluzione dell'equazione di Laplace deve risultare
\begin{equation}
	0=\frac{\partial^2}{\partial\eta\partial\eta^*}\sum_{p=0}^lc_p\eta^p(\eta^*)^{p-l}=\sum_{p=0}^lc_p(l-p)p\eta^{p-1}(\eta^*)^{l-p-1}
\end{equation}
ossia $p(l-p)c_p=0$ per ogni $p=0,\dots,l$, a meno che $p=l$ o $l=0$.
Allora rimane soltanto $u(\eta,\eta^*)=c_0(\eta^*)^l+c_l\eta^l$, e tornando alle variabili reali abbiamo dunque
\begin{equation}
	\begin{gathered}
		c_0(\eta^*)^l=c_0(x-iy)^l=c_0r^l(\cos\phi-i\sin\phi)^l=c_0r^le^{-il\phi},\\
		c_l\eta^l=c_l(x+iy)^l=c_lr^l(\cos\phi+i\sin\phi)^l=c_lr^le^{il\phi}.
	\end{gathered}
\end{equation}

Tornando al problema generale, in una dimensione generica, alla luce di questi risultati è sensato carcare delle soluzioni, in coordinate polari, $u(r,\phi_1,\dots,\phi_{n-1})$ che siano fattorizzate come $r^lY(\phi_1,\dots,\phi_{n-1})$.
Inoltre dalla \eqref{eq:laplace-parte-radiale}, dopo aver semplificato la funzione $Y$, abbiamo
\begin{equation}
	0=-\frac1{r^{d-1}}\drp{}{r}r^{d-1}\drp{}{r}r^l=-l\frac1{r^{d-1}}\drp{}{r}r^{d-1+l-1}=-l(d+l-2)\frac1{r^{d-1}}r^{d-l-2}=-l(d+l-2)r^{l-2}
\end{equation}
perciò la funzione che dà gli autovalori di $L^2$ in dimensione $d$ è $g(l)=l(d+l-2)$.
In particolare, per $d=2$ troviamo $g(l)=l^2$, e infatti il generatore di $L^2$ è unico in $\R^2$ (c'è solo una componente del momento angolare), e tale operatore ha come autovalori $\pm l$, a cui corrispondono le autofunzioni $c_0r^le^{-il\phi}$ e $c_lr^le^{il\phi}$ trovate in precedenza.

\paragraph{Equazione di Laplace in $\R^3$}
Per risolvere l'equazione $\lap u(x,y,z)=0$ effettuiamo la stessa sostituzione nel caso bidimensionale sulle coordinate $x,y$ lasciando invariata la terza.
Un polinomio omogeneo di grado $l$ nelle variabili $\eta,\eta^*,z$ è della forma
\begin{equation}
	u_l(\eta,\eta^*,z)=\sum_{p,q=0}^lc_{p,q}\eta^p(\eta^*)^qz^{l-p-q}
\end{equation}
mentre l'operatore laplaciano si estende facilmente dal caso precedente come $\lap=4\frac{\partial}{\partial\eta\partial\eta^*}+\frac{\partial^2}{\partial z^2}$: il polinomio $u_l$ è soluzione dell'equazione di Laplace, dunque, se
\begin{equation}
	\begin{split}
		0&=\sum_{p,q=0}^l4c_{p,q}\frac{\partial^2}{\partial\eta\partial\eta^*}\eta^p(\eta^*)^qz^{l-p-q}+\sum_{p,q=0}^lc_{p,q}\ddrp{}{z}\eta^p(\eta^*)^qz^{l-p-q}=\\
		&=\sum_{p,q=0}^l4c_{p,q}pq\eta^{p-1}(\eta^*)^{q-1}z^{l-p-q}+\sum_{p,q=0}^lc_{p,q}(l-p-q)(l-p-q-1)\eta^p(\eta^*)^qz^{l-p-q-2}
	\end{split}
\end{equation}
e riscalando gli indici della prima somma risulta
\begin{equation}
	\sum_{p,q=-1}^{l-1}4c_{p+1,q+1}(p+1)(q+1)\eta^{p}(\eta^*)^{q}z^{l-p-q-2}=-\sum_{p,q=0}^lc_{p,q}(l-p-q)(l-p-q-1)\eta^p(\eta^*)^qz^{l-p-q-2}
\end{equation}
da cui otteniamo l'equazione di riccorrenza
\begin{equation}
	c_{p+1,q+1}=-\frac{(l-p-q)(l-p-q-2)}{4(p+1)(q+1)}c_{p,q}.
	\label{eq:ricorrenza-coefficienti-equazione-laplace}
\end{equation}
Possiamo disporre i coefficienti $c_{p,q}$ su un piano, in cui risulteranno limitati dagli assi $p=0$, $q=0$ e dalla retta $p+q=l$.
Prendendo uno dei punti nel grafico, il termine successivo nella ricorrenza si ottiene aumentando di 1 entrambi gli indici, muovendosi dunque in diagonale nel grafico fino a raggiungere il bordo.
I coefficienti sui due assi possono essere di conseguenza assunti come condizioni iniziali per le soluzioni: tutti gli altri si ottengono da questi e dalla \eqref{eq:ricorrenza-coefficienti-equazione-laplace}.
Queste condizioni iniziali sono in tutti $2l+1$, che è quindi il numero di soluzioni indipendenti dell'equazione di Laplace.
Indichiamo dunque con i due numeri $l$ e $m$, dove $m$ assume uno di questi $2l+1$ valori, le varie soluzioni indipendenti dell'equazione differenziale, che saranno quindi della forma $r^lY_{l,m}(\phi,\theta)$.

\paragraph{Armoniche sferiche}
Le funzioni $Y_{l,m}$ sono dette \emph{armoniche sferiche}.
Indichiamo con $Y_{l,m}$ la soluzione che ha come condizione iniziale $c_{m,0}$ e con $Y_{l,-m}$ la soluzione con condizione iniziale $c_{0,m}$.
La funzione $Y_{0,0}$ è costante, e corrisponde alla rappresentazione del gruppo delle rotazioni di peso $l=0$.
Affinch\'e le armoniche sferiche siano normalizzate, devono essere integrate sull'angolo solido di $4\pi$, perciò ad esempio $Y_{0,0}=\frac1{\sqrt{4\pi}}$.
Guardiamo invece le armoniche sferiche con $l=1$ abbiamo
\begin{equation}
	\begin{aligned}
		rY_{1,-1}=r\sin\theta e^{-i\phi}=x-iy\\
		rY_{1,0}=r\cos\theta=z\\
		rY_{1,1}=r\sin\theta e^{-i\phi}=x+iy
	\end{aligned}
	\label{eq:armoniche-sferiche-1}
\end{equation}
che sono combinazioni lineari (complesse) delle tre componenti del vettore posizione: queste tre funzioni si trasformano dunque come vettori sotto l'effetto di una rotazione.
Prendiamo ora l'armonica $Y_{l,l}$: troviamo che $r^lY_{l,l}=\eta^l=(x+iy)^l=r^l\sin^l\theta e^{il\phi}$ che è dunque anche autofunzione di $L_3$.
Analogamente, lo è anche $r^lY_{l,-l}=(\eta^*)^l=r^l\sin^l\theta e^{-il\phi}$.
In generale, risulta
\begin{equation}
	r^lY_{l,m}(\phi,\theta)=\sum_kc_{m+k,k}\eta^{m+k}(\eta^*)^kz^{l-m-2k}=r^l\sum_kc_{m+k,k}\sin^{m+2k}\theta\cos^{l-m-2k}\theta e^{im\phi}
\end{equation}
e si nota subito che è un'autofunzione di $L_3$ con autovalore $m$.
Se poi $m$ è pari il termine $\sin\theta$ è elevato ad una potenza pari, dunque si ha una funzione di $\sin^2\theta=1-\cos^2\theta$: la funzione $r^lY_{l,m}(\phi,\theta)$, nella variabile $\theta$, è allora un polinomio in $\cos\theta$.
Una volta normalizzato, risulta
\begin{equation}
	Y_{l,m}(\phi,\theta)=\sqrt{\frac{2l+1}{4\pi}\frac{(l-\abs{m})!}{(l+\abs{m})!}}e^{im\phi}P_l^{\abs{m}}(\cos\theta)
	\label{eq:armoniche-sferiche-funzioni-associate-legendre}
\end{equation}
indicando con $P_l^{\abs{m}}$ la \emph{funzione associata di Legendre} (per $m$ pari), definita come
\begin{equation}
	P_l^k(x)=(-1)^k(1-x^2)^{\frac{k}2}\frac{\dd^k}{\dd x^k}P_l(x)
	\label{eq:funzione-associata-legendre}
\end{equation}
dove $P_l(x)$ è il \emph{polinomio di Legendre} di grado $l$: si vede che $P_l^k$ è un polinomio solo se $k$ è pari, altrimenti compaiono delle radici nella sua espressione.
I polinomi di Legendre formano un insieme ortogonale nel dominio $[-1,1]$: risulta
\begin{equation}
	\begin{gathered}
		\int_{-1}^1P_l(x)P_k(x)\,\dd x=\frac{2}{2l+1}\delta_{lk}\\
		\int_{-1}^1\frac1{1-x^2}P_l^m(x)P_l^n(x)\,\dd x=
		\begin{cases}
			0						&m\ne n\\
			\frac{(l+m)!}{m(l-m)!}	&m=n\ne 0\\
			+\infty					&m=n=0
		\end{cases}\\
		\int_{-1}^1P_l^m(x)P_k^n(x)\,\dd x=\frac{2(l+m)!}{(2l+1)(l-m)!}\delta_{lk}.
	\end{gathered}
	\label{eq:ortogonalita-legendre}
\end{equation}

\section{Composizione di momenti angolari}
Prendiamo due momenti angolari $\op{\vec J}_1$ e $\op{\vec J}_2$ di due sistemi fisici differenti, in tutta generalità.
Per ciascuno dei due valgono le regole di commutazione date dalla \eqref{eq:commutazione-momento-angolare}; poich\'e inoltre i due operatori fanno riferimento a sistemi fisici diversi commutano (ad esempio in un sistema di due particelle la misura del momento angolare orbitale di una delle due non influisce sulle misure dell'altra) dunque $[\op J_{1i},\op J_{2j}]=0$ per ogni $i,j$.
Queste relazioni definiscono la somma diretta di due algebre $\mathfrak{su}(2)$ (o equivalentemente di $\mathfrak{so}(3)$), una per ciascun operatore, cioè dell'algebra $\mathfrak{su}(2)\oplus\mathfrak{su}(2)$ che è associata al gruppo di Lie $SU(2)\otimes SU(2)$.
Il prodotto tensoriale dei due $SU(2)$ indica come i due gruppi delle rotazioni siano in un certo senso indipendenti.

Consideriamo ora l'insieme di osservabili $\{\op{\vec J}_1^2,\op{\vec J}_2^2,\op J_{13},\op J_{23}\}$, che a meno di altre osservabili forma un sistema completo (di osservabili compatibili).
Definiamo il \emph{momento angolare totale} del sistema composto dal sistema 1 e 2 come\footnote{
    La ragione per cui il momento angolare totale è definito in questo modo, detto \emph{coprodotto} dei due $\op{\vec J}_i$, e non con una semplice somma sarà chiara nel capitolo \ref{ch:multi} quando tratteremo i sistemi con più particelle.
    Per il momento, come giustificazione si può prendere il fatto che solo con questa definizione si ha che
    \begin{equation}
        \exp\Bigl(-\frac{i}{\hbar}\theta\scalar{\axis}{\op{\vec J}}\Bigr)=
        \exp\Bigl(-\frac{i}{\hbar}\theta\scalar{\axis}{\op{\vec J_1}}\Bigr) \otimes \exp\Bigl(-\frac{i}{\hbar}\theta\scalar{\axis}{\op{\vec J_2}}\Bigr)
    \end{equation}
    mentre non è vero per $\op{\vec J}_1+\op{\vec J}_2$.
}
\begin{equation}
    \op{\vec J} \defeq \op{\vec J}_1\otimes\op 1 + \op 1\otimes\op{\vec J}_2
    \label{eq:momento-angolare-totale}
\end{equation}
che soddisfa le relazioni di commutazione $[\op J_i,\op J_j]=i\hbar\epsilon_{ijk}\op J_k$, ed è cos\`i il generatore delle rotazioni di tutto il sistema: è questa la grandezza che si conserva se il sistema è isolato, per l'isotropia dello spazio, e non i due singoli $\op{\vec J}_i$.\footnote{
	Qui la notazione è un po' ambigua: da una parte abbiamo i due operatori $\op{\vec J}_1$ e $\op{\vec J}_2$ dei momenti angolari dei due sistemi, e dall'altra le componenti $\op J_i$ del momento angolare totale.
	Si noti però che i primi due sono in grassetto, che è usato per indicare dei vettori, perciò dovrebbe risultare chiaro che $\op{\vec J}_k$ è un vettore e si riferisce perciò a uno dei sistemi, mentre $\op J_k$ è la componente di un vettore, in questo caso del momento totale $\op{\vec J}$.
	Le componenti dei momenti angolari di ciascun sistema sono indicate con un doppio indice, come $\op J_{12}$.
}
Troviamo poi le altre relazioni di commutazione $[\op J_i,\op{\vec J}_1^2]=0$ e $[\op J_i,\op{\vec J}_2^2]=0$, in quanto i quadrati $\op{\vec J}^2$, $\op{\vec J}_1^2$ e $\op{\vec J}_2^2$ dei momenti angolari sono quantità scalari cioè invarianti per rotazioni (un calcolo diretto verifica comunque tutto ciò).
Per lo stesso motivo deve essere poi $[\op{\vec J}^2,\op J_{13}]\ne 0$, e lo stesso con $\op J_{23}$, poich\'e le rotazioni di uno solo dei due sistemi \emph{non} lasciano invariate (in generale) le grandezze scalari.
Per costruire un altro sistema completo di osservabili compatibili, usando i nuovi operatori $\op{\vec J}$, dobbiamo allora prendere l'insieme $\{\op{\vec J}_1^2,\op{\vec J}_2^2,\op{\vec J}^2,\op J_3\}$, sempre a meno di altre osservabili.
Con queste scelte troviamo quindi due basi per lo spazio degli stati: ignorando i numeri quantici riferiti alle altre osservabili, abbiamo
\begin{itemize}
	\item la base con stati del tipo $\ket{j_1,m_1,j_2,m_2}$, dove $j_1$ è il numero quantico dell'autovalore di $\op{\vec J}_1^2$, $m_1$ di $\op J_{13}$ e cos\`i via;
	\item la base con stati $\ket{j_1,j_2,j,m}$, dove $j$ e $m$ si riferiscono al momento angolare totale.
\end{itemize}
La prima è detta \emph{base disaccoppiata}, mentre la seconda \emph{accoppiata}.
Gli elementi della prima base, dato che le due coppie $j_i,m_i$ di autovalori si riferiscono a due operatori su spazi distinti, si scrivono anche come $\ket{j_1,m_1}\otimes\ket{j_2,m_2}$, coerentemente con il fatto che il gruppo delle rotazioni del sistema è $SU(2)\otimes SU(2)$: il gruppo $SU(2)$ ``di sinistra'' agisce sugli stati $\ket{j_1,m_1}$, mentre quello ``di destra'' sugli stati $\ket{j_2,m_2}$, indipendentemente l'uno dall'altro.
Il gruppo prodotto $SU(2)\otimes SU(2)$ è però il gruppo di simmetria del sistema totale, e in generale le sue rappresentazioni non sono irriducibili, ma si possono scomporre nella somma di tante rappresentazioni di dimensione minore; di conseguenza lo spazio di rappresentazione, dato dalla base accoppiata, si suddivide in tanti sottospazi, ognuno caratterizzato dal peso $j$ della rappresentazione associata.
La chiave del problema è trovare i vari pesi $j$ delle nuove rappresentazioni, che corrispondono agli autovalori $j(j+1)\hbar^2$ che il momento angolare totale $\op{\vec J}$ può assumere a partire dai due $\op{\vec J}_1$ e $\op{\vec J}_2$.
Il passaggio tra le due basi definite è dato dalla trasformazione
\begin{equation}
    \ket{j,m}=\sum_{m_1=-j_1}^{j_1}\sum_{m_2=-j_2}^{j_2}\ket{j_1,m_1,j_2,m_2}\braket{j_1,m_1,j_2,m_2}{j,m}
	\label{eq:sviluppo-clebsch-gordan}
\end{equation}
(sottintendendo $j_1,j_2$, che sono fissati, nello stato $\ket{j,m}$) i cui coefficienti $\braket{j_1,m_1,j_2,m_2}{j,m}$, che formano una matrice unitaria dato che sono relativi al passaggio tra due basi ortonormali, sono chiamati \emph{coefficienti di Clebsch-Gordan}.
Notiamo subito, applicando $\op J_3=\op J_{13}\otimes\op 1+\op 1\otimes\op J_{23}$ alla \eqref{eq:sviluppo-clebsch-gordan}, che
\begin{equation}
    \begin{aligned}
        J_3\ket{j,m}&=\sum_{m_1=-j_1}^{j_1}\sum_{m_2=-j_2}^{j_2}\braket{j_1,m_1,j_2,m_2}{j,m}(\op J_{13}\otimes\op 1+\op 1\otimes\op J_{23})\ket{j_1,m_1,j_2,m_2}\\
        m\hbar\ket{j,m}&=\sum_{m_1=-j_1}^{j_1}\sum_{m_2=-j_2}^{j_2}\braket{j_1,m_1,j_2,m_2}{j,m}(m_1+m_2)\hbar\ket{j_1,m_1,j_2,m_2}\\
    \end{aligned}
\end{equation}
quindi i coefficienti di Clebsch-Gordan sono nulli se $m\ne m_1+m_2$.

Guardiamo ora ad alcuni semplici esempi di corrispondenza tra le due basi.
Fissiamo i due numeri $j_1$ e $j_2$, ottenendo un sottospazio di dimensione $(2j_1+1)(2j_2+1)$ in cui variano i due indici $-j_1\le m_1\le j_1$ e $-j_2\le m_2\le j_2$.
Con la base accoppiata, invece, l'unico indice di $\op J_3$ è $m$ che può variare tra $-j$ e $j$, ottenendo $2j+1$ stati.
Dato che deve risultare $m=m_1+m_2$, il massimo valore di $m$ può solo essere la somma dei massimi valori possibili di $m_1$ e $m_2$, ossia $j_1+j_2$.
Si ha inoltre che $j\ge m$, ma allora deve essere necessariamente $j=j_1+j_2$, poich\'e altrimenti sarebbero ammessi valori di $m_1+m_2$ maggiori di $j_1+j_2$ il che non è possibile con le combinazioni a disposizione.
Lo stato $\ket{j_1,m_1=j_1,j_2,m_2=j_2}$ coincide con $\ket{j_1,j_2,j=j_1+j_2,m=j}$.
Consideriamo allora l'autovalore subito minore, che ha $m=j_1+j_2-1$: a tale numero corrispondono gli stati, nella base disaccoppiata, $\ket{j_1,m_1=j_1-1,j_2,m_2=j_2}$ e $\ket{j_1,m_1=j_1,j_2,m_2=j_2-1}$ che possono dare tale $m$; nella base accoppiata troviamo invece $\ket{j_1,j_2,j=j_1+j_2,m=j-1}$ e un altro ad esso ortogonale, che si troverà allora nel sottospazio con $j$ diminuito di 1, ossia $\ket{j_1,j_2,j=j_1+j_2-1,m=j}$.
Scendendo ulteriormente a $m=j_1+j_2-2$ troviamo come prima tre stati i cui $m_1,m_2$ possono dare questo risultato; nella base accoppiata troviamo invece gli stati del tipo $\ket{j_1,j_2,j=j_1+j_2-k,m=j-2}$ con $k=0,1,2$.
Possiamo continuare cos\`i finch\'e è possibile scegliere i numeri $m_1$ e $m_2$, dato che sono in un numero finito: il minimo valore che $m$ può assumere risulta cos\`i $j=\abs{j_1-j_2}$.
In effetti, solo con questo valore possiamo avere l'uguaglianza
\begin{equation}
	\sum_{j=\abs{j_1-j_2}}^{j_1+j_2}(2j+1)=(2j_1+1)(2j_2+1)
\end{equation}
che mostra come i due spazi hanno davvero la stessa dimensione.
In altri termini, indicata la rappresentazione con il suo peso $j$, la rappresentazione prodotto $j_1\otimes j_2$ si scompone nella somma
\begin{equation}
	j_1\otimes j_2=(j_1+j_2)\oplus(j_1+j_2-1)\oplus\cdots\oplus\abs{j_1-j_2}
\end{equation}
e gli stati della base accoppiata sono $\ket{j_1,j_2,j,m}$ con $\abs{j_1-j_2}\le j\le j_1+j_2$ e $-j\le m\le j$.

Calcoliamo i coefficienti di Clebsch-Gordan per due momenti angolari $j_1=j_2=\frac12$: la base disaccoppiata è $\ket{\frac12,m_1,\frac12,m_2}$ con $m_1$ e $m_2$ che variano tra $-\frac12$ e $\frac12$, mentre quella accoppiata è composta da $\ket{\frac12,\frac12,s,m}$ con $s=0,1$ e $m$ che varia tra $-s$ e $s$; per brevità sottintenderemo i due valori di $j_1$ e $j_2$, e scriveremo $\ket{\pm,\pm}\defeq\ket{\frac12,\pm\frac12,\frac12,\pm\frac12}$.
Prendiamo lo stato $\ket{1,1}$, nella base accoppiata: dato che $m=1$ si avrà per forza $m_1=m_2=\frac12$, quindi
\begin{equation}
    \ket{1,1}=\ket{+,+}.
\end{equation}
Da questo prendiamo l'operatore di discesa $\op J_{1-}\otimes\op 1+\op 1\otimes\op J_{2+}$ su $\ket{+,+}$, e otteniamo lo stato $\ket{+,-}+\ket{-,+}$; esso ha ancora $j=1$ (gli operatori di salite e discesa non modificano $j$) e ha $m=0$ pertanto, normalizzato, è
\begin{equation}
    \ket{1,0}=\frac1{\sqrt{2}}(\ket{+,-}+\ket{-,+}).
\end{equation}
Applicando nuovamente l'operatore di discesa si ottiene
\begin{equation}
    \ket{1,-1}=\ket{-,-}.
\end{equation}
Rimane dunque un solo stato, $\ket{0,0}$, ortogonale a questi tre: con il primo e il terzo non si ottiene niente, dato che hanno $m$ differenti; imponendo invece l'ortogonalità con il secondo si ottiene
\begin{equation}
    \ket{0,0}=\frac1{\sqrt{2}}(\ket{+,-}-\ket{-,+}).
\end{equation}
La matrice che riassume i sedici coefficienti di Clebsch-Gordan nella decomposizione $\frac12\otimes\frac12=1\oplus 0$ è dunque, ordinando le basi come $\{\ket{-,-},\ket{+,-},\ket{-,+},\ket{+,+}\}$ e $\{\ket{0,0},\ket{1,1},\ket{1,0},\ket{1,-1}\}$ è
\begin{equation}
    \begin{pmatrix}
        0                 & 0 & 0                & 1 \\
        \frac1{\sqrt{2}}  & 0 & \frac1{\sqrt{2}} & 0 \\
        -\frac1{\sqrt{2}} & 0 & \frac1{\sqrt{2}} & 0 \\
        0                 & 1 & 0                & 0 
    \end{pmatrix}.
    \label{eq:clebsch-gordan-spin-1/2}
\end{equation}
